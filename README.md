# RSGAN
RECURRENT STACKED GENERATIVE ADVERSARIAL NETWORK FOR CONDITIONAL VIDEO GENERATION

Generating video frames based on a pre-condition is a challenging problem and requires understanding of per frame contents and visual dynamics and their relevacies to the pre-condition. 
In this paper, we propose a novel Recurrent Stacked Generative Adversarial Network (RSGAN) based model to generate video frames based on a given pre-condition. 
The pre-condition can be anything related to the generated video, like- action classes, sentence descriptor, fMRI signal, etc.
In our knowledge, this is the first work to address the problem of conditional video generation using adversarial network.

**Successful examples:**

Bird-1, ![Bird-1](/examples/bird1.jpg)

Bird-5, ![Bird-5](/examples/bird5.jpg)

Flower-1, ![Flower-1](/examples/flower1.jpg)

&nbsp;

**Bad examples:**

People are standing, ![Standing-1](/hard_examples/UCF101-stand.jpg)

People pointing finger to other, ![Pointing-1](/hard_examples/point%20finger%20at%20the%20other%20person.png)

Someone is writing something, ![Writing-1](/hard_examples/writing.png)

&nbsp;

Poster [[LINK]](/RSGAN2017.poster.pdf), paper [[LINK]](/Nayem.RSGAN.CV.2017.pdf).


