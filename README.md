# RSGAN
RECURRENT STACKED GENERATIVE ADVERSARIAL NETWORK FOR CONDITIONAL VIDEO GENERATION

Generating video frames based on a pre-condition is a challenging problem and requires understanding of per frame contents and visual dynamics and their relevacies to the pre-condition. 
In this paper, we propose a novel Recurrent Stacked Generative Adversarial Network (RSGAN) based model to generate video frames based on a given pre-condition. 
The pre-condition can be anything related to the generated video, like- action classes, sentence descriptor, fMRI signal, etc.
In our knowledge, this is the first work to address the problem of conditional video generation using adversarial network.

Successful examples,

![Bird-1](/examples/bird1.png)

Poster [[LINK]](/RSGAN2017.poster.pdf), paper [[LINK]](/Nayem.RSGAN.CV.2017.pdf).


